{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### agent-101: 让AI自由组织工具回答问题\n",
    "\n",
    "智能体在回答问题的时候，不一定只调用一个工具，而是可能需要综合调用多个工具。\n",
    "比如：\n",
    "- \"帮我下载arxiv上与智能体相关的论文\"包含搜索+下载两个动作，需要用到search和download两个工具\n",
    "- \"帮我全网搜索与量化投资相关的资料\"就可能包含必应搜索、arxiv搜索、知网搜索等\n",
    "\n",
    "这时候我们就需要指引工具选择智能体在选择工具的时候，输出一个工具列表而不是单一的工具。\n",
    "比如：需要做多次搜索的时候，就需要输出类似如下内容：\n",
    "\n",
    "\"tools\": [\"get_bing_searched_results(keyword='大语言模型', max_results=5)\", \"get_bing_searched_results(keyword='Large Language Model', max_results=5)\", \"get_arxiv_papers(keyword='大语言模型', max_results=5, sort_by='relevance')\", \"search_cnki(keyword='大语言模型', num_pages=1)\"]\n",
    "\n",
    "选择三个工具，做了四次搜索\n",
    "\n",
    "在这个智能体里边，更体现了大语言模型的智能，也就是规划能力。\n",
    "我们给它提供足够多的工具，它能自由地选择工具，获取信息，回答我们的问题。\n",
    "\n",
    "图中的例子里，我让我的智能体执行了全网搜索回答问题，以及搜索并下载论文到本地的功能。\n",
    "- 全网搜索，调用了两个工具，搜索到了一万二个字的结果，让AI进行总结。\n",
    "- 搜索并下载论文这个功能，有个比较复杂的地方就是，AI需要先搜索到论文的链接之后，才知道要下载的链接是什么，一开始的download肯定是不知道具体的参数要填什么的（也就是链接）。因此需要在搜索总结之后，再让tool agent选择工具，填入具体的参数才能执行下载。\n",
    "\n",
    "\n",
    "到目前为止，基本上我们已经逐步搭建了比较完善的智能体系统：大模型+工具选择+计划+反思。\n",
    "依然缺失的是记忆模块，我们下期再继续（挖坑ing）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to-do\n",
    "- 搜索-下载-阅读\n",
    "**TOP PRIORITY**\n",
    "- 规划能力\n",
    "- 记忆能力\n",
    "\n",
    "**复杂RAG**\n",
    "- 找到RAG评测数据集/知识库\n",
    "- 将RAG做细\n",
    "- 阅读开源框架（GraphRAG）\n",
    "- Elastic Search\n",
    "- faiss向量数据库\n",
    "\n",
    "**企业微信小助手**\n",
    "- 下载论文到本地的功能 √\n",
    "- 聊天界面需要增加文件上传的功能 √\n",
    "- 自动构建AT策略\n",
    "- 自动挖掘因子\n",
    "- 记住我们的喜好（参考mem0）\n",
    "- 自主上网学习最新知识，保存到知识库，随时调取（参考GraphRAG构建知识图谱）\n",
    "- 自我进化，每次都能输出最高质量的回答\n",
    "- 完成论文中的实证部分\n",
    "- 头脑风暴获取极具创意的想法\n",
    "- 自主学习并构建全新的工具\n",
    "- 多工具同时调用，汇总信息，给出答案\n",
    "- 需要增加一个复杂问题解决流程，让智能体多次调用工具，综合多个工具的结果，最后给出答案。（使用\"[END]\"标记作为结束）\n",
    "- 增加一个网页界面\n",
    "- 随着聊天变长，随机遗忘不重要的信息。（可设计一个重要程度判断模型）\n",
    "- 文件上传分析（读取文件、分析文件）\n",
    "- 代码运行需要增加代码运行结果的展示\n",
    "- 需要增加动态修改系统提示词的功能\n",
    "- 增加标准工具箱，让新增工具的时候更方便\n",
    "- files 多文件处理\n",
    "- 知识图谱构建\n",
    "- 路径规划\n",
    "\n",
    "\n",
    "- 流式输出的时候增加多层思考过程，然后在最后修改/提供思路\n",
    "\n",
    "**ERGENT**\n",
    "- 工具规范调用（Mem0的mem0/llms/utils/tools.py文件）\n",
    "    - 实现任意选择工具的功能（无工具、自选工具）\n",
    "- 记忆功能\n",
    "- 多工具转换为多智能体\n",
    "- \n",
    "\n",
    "##### 最终实现\n",
    "- 让智能体根据问题，自由调用工具实现任何问题\n",
    "- 使用while - end 循环\n",
    "\n",
    "- GPT-4o长输出：gpt-4o-64k-output-alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **多工具调用智能体**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：什么是大语言模型？\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:15:08,128 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tools\": [\"chat\"]\n",
      "}\n",
      "```需要调用工具数量：1 \n",
      "\n",
      "第1个工具：chat\n",
      "\n",
      "====================工具调用结束, 获取信息字数：0，开始回答====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 21:15:10,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据我找到的信息，我认为大语言模型（Large Language Model, LLM）是一种基于机器学习的人工智能模型，专门用于处理和生成自然语言文本。这些模型是通过在大量的文本数据上进行训练来掌握语言的结构、语法、语义和背景知识。其主要特点包括：\n",
      "\n",
      "1. **规模庞大**：大语言模型通常包含非常多的参数，比如数十亿到上千亿个参数，这使得它们有能力捕获更加复杂的语言模式。\n",
      "\n",
      "2. **深度学习架构**：它们主要基于深度学习架构，例如Transformers，这种架构使模型能有效地处理长距离的依赖关系和上下文信息。\n",
      "\n",
      "3. **预训练与微调**：大语言模型通常先在广泛的语料库上进行无监督的预训练，学习到一般的语言特征，然后通过微调（fine-tuning）在特定任务（如翻译、文本生成、情感分析等）上进行调整。\n",
      "\n",
      "4. **生成与理解能力**：这些模型能够生成符合语法且有逻辑的文本，回答问题，翻译语言，以及执行其他自然语言处理任务。\n",
      "\n",
      "5. **多领域应用**：大语言模型可以应用于多个领域，包括但不限于客服自动化、内容创作、翻译服务、代码生成、教育等。\n",
      "\n",
      "然而，大语言模型也面临一些挑战，比如在生成内容中的偏见与不准确性，计算资源消耗大，以及在某些任务上的不确定性或不稳定性。\n",
      "\n",
      "# 相关链接\n",
      "这里没有提供具体的链接，如果需要进一步深入的信息或者引用，可以请求具体的文献或者在线资源。"
     ]
    }
   ],
   "source": [
    "from growing_agent_tools.llm_api import * \n",
    "from growing_agent_tools.json_tool import *\n",
    "from growing_agent_tools.code_interpreter import * \n",
    "\n",
    "from growing_agent_tools.search_bing import *\n",
    "from growing_agent_tools.search_arxiv import *\n",
    "from growing_agent_tools.search_cnki import *\n",
    "from growing_agent_tools.text2jupyter import *\n",
    "from growing_agent_tools.pdf_reader import * \n",
    "from growing_agent_tools.download_arxiv_papers import *\n",
    "\n",
    "class AllToolsAgent:\n",
    "    \n",
    "    def __init__(self, agent_name=\"AllTools\"\n",
    "                 , model=\"glm-4-0520\"\n",
    "                 , temperature=0.9):\n",
    "        self.name = agent_name\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # 如果不存在files文件夹，则创建\n",
    "        if not os.path.exists(\"files\"):\n",
    "            os.makedirs(\"files\")\n",
    "        # 获取files文件夹下的所有文件\n",
    "        files = os.listdir(\"files\")\n",
    "        self.files = [f for f in files if f.endswith(\".pdf\")]\n",
    "                \n",
    "        # 工具选择系统\n",
    "        self.tool_system_prompt = self.get_prompt(\"prompts/tools_system_prompt.txt\")\n",
    "        self.tool_system_prompt = self.tool_system_prompt.format(files=self.files)\n",
    "        self.tool_conversations = [{\"role\": \"system\", \"content\": self.tool_system_prompt}]\n",
    "        \n",
    "        # 回答系统\n",
    "        self.agent_system_prompt = '''你必须尽可能详细地回答我的问题。'''\n",
    "        self.agent_conversations = [{\"role\": \"system\", \"content\": self.agent_system_prompt}]\n",
    "        \n",
    "    # 提示词读取\n",
    "    def get_prompt(self, path):\n",
    "        with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "            prompt = file.read()\n",
    "        return prompt\n",
    "    \n",
    "    # 依据聊天记录回答\n",
    "    def get_answer_converse_yield(self):\n",
    "        ans = \"\"\n",
    "        for char in get_llm_answer_converse(self.agent_conversations, self.model, self.temperature):\n",
    "            ans += char\n",
    "            yield char\n",
    "\n",
    "    # 选择工具\n",
    "    def select_tools(self, question, tool_model=\"deepseek-chat\"):\n",
    "        # 注意事项\n",
    "        notice = '''\n",
    "# 注意\n",
    "- 你的输出必须是一个json格式的字符串，这个json仅包含tool这个key，value是你选择的工具列表（每个工具包含函数名+参数）\n",
    "- 你的json必须以```json开头，以```结尾\n",
    "- 除非是你不熟悉的话题，否则不需要使用必应搜索工具，直接回答问题即可\n",
    "- 除非是需要查找论文，否则搜索的时候不需要使用arxiv工具\n",
    "- 你只需要输出json即可，不需要其他任何额外的输出\n",
    "- 如果前面已经调用过提取PDF的工具，后续不需要再次调用，直接选择chat工具即可\n",
    "'''\n",
    "        # 选择工具\n",
    "        self.tool_conversations.append({\"role\": \"user\", \"content\": \"我现在要解决以下问题：\\n\" + question + \"\\n帮我选择合适的工具函数，以json格式发给我。\" + notice})\n",
    "        ans = \"\"\n",
    "        for char in get_llm_answer_converse(self.tool_conversations, tool_model, self.temperature):\n",
    "            ans += char\n",
    "            print(char, end='', flush=True)\n",
    "        self.tool_conversations.append({\"role\": \"assistant\", \"content\": ans})\n",
    "        tools = get_json(ans)[\"tools\"]\n",
    "        return tools\n",
    "    \n",
    "    # 工作流\n",
    "    def work_flow(self, question, tool_model=\"deepseek-chat\"):\n",
    "        total_info = \"\"\n",
    "        # 选择工具\n",
    "        tools = self.select_tools(question, tool_model)\n",
    "        print(f\"需要调用工具数量：{len(tools)} \\n\")\n",
    "        for i,tool in enumerate(tools):\n",
    "            print(f\"第{i+1}个工具：{tool}\")\n",
    "            \n",
    "        for tool in tools:   \n",
    "            # 如果tool不是以download开头\n",
    "            if not tool.startswith(\"download\"):                    \n",
    "                # arXiv搜索 下载arxiv论文 搜索CNKI 搜索必应 获取必应搜索结果 提取PDF文本\n",
    "                if tool.startswith(\"get_arxiv_papers\") or tool.startswith(\"search_cnki\") or tool.startswith(\"get_bing_searched_results\") or tool.startswith(\"extract_clean_text_from_pdf\"):\n",
    "                    yield \"正在执行：\\n\" + tool + \"\\n\"\n",
    "                    result, _ = run_code_v2(tool, globals=globals())\n",
    "                    print(f\"工具运行结果如下：{str(result)[:1000]}\\n\")\n",
    "                    total_info += str(result) + \"\\n\"\n",
    "                \n",
    "                # 深度数据分析\n",
    "                # code interpreter\n",
    "                elif tool.startswith(\"run_code_v2\"):\n",
    "                    yield \"正在运行代码...\"\n",
    "                    # 写代码\n",
    "                    self.agent_conversations.append({\"role\": \"user\", \"content\": question})\n",
    "                    ans = \"\"\n",
    "                    for char in auto_code_running_modify(question, self.model):\n",
    "                        yield char\n",
    "                        ans += char\n",
    "                    total_info += ans + \"\\n=====================\\n\"   \n",
    "                                            \n",
    "                prompt = '''\n",
    "# 你的任务\n",
    "根据提供的信息，回答我的问题\n",
    "\n",
    "# 你帮我找到了以下信息：\n",
    "\"\"\"\n",
    "{total_info}\n",
    "\"\"\"\n",
    "\n",
    "# 我的问题\n",
    "\"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# 你的工作流\n",
    "1. 你必须首先详细回答我上述的问题，不需要担心token限制，并且你必须以类似如下的格式回答我的问题：\n",
    "\"根据我找到的信息，我认为......\"\n",
    "2. 然后在最后简要列举你搜索到的所有信息+链接，作为参考\n",
    "\n",
    "# 参考输出\n",
    "根据我找到的信息...\n",
    "\n",
    "# 相关链接\n",
    "- [链接1](https://...)\n",
    "...\n",
    "\n",
    "# 注意\n",
    "- 相关链接只需要在第二步展示即可，第一步不需要提供链接\n",
    "- 你拥有下载文件的工具，如果需要下载文件，则告诉我请稍后即可\n",
    "现在，请回答我的问题：\n",
    "{question}\n",
    "'''\n",
    "                prompt = prompt.format(total_info=total_info, question=question)\n",
    "                self.tool_conversations.append({\"role\": \"user\", \"content\": prompt})    \n",
    "                self.agent_conversations.append({\"role\": \"user\", \"content\": prompt})   \n",
    "                print(\"\\n\" + \"=\"*20 + f\"工具调用结束, 获取信息字数：{len(total_info)}，开始回答\" + \"=\"*20 + \"\\n\") \n",
    "                ans = \"\"\n",
    "                for char in self.get_answer_converse_yield():\n",
    "                    yield char\n",
    "                    ans += char\n",
    "                self.tool_conversations.append({\"role\": \"assistant\", \"content\": ans[:1000]})\n",
    "                self.agent_conversations.append({\"role\": \"assistant\", \"content\": ans})      \n",
    "            else:\n",
    "                # 下载文件\n",
    "                question = \"现在，请根据上述搜索到的链接，编写函数以及参数，给出json格式的工具\"\n",
    "                tools = self.select_tools(question, tool_model)\n",
    "                yield \"\\n正在执行：\\n\" + tools\n",
    "                [0] + \"\\n\"\n",
    "                result, _ = run_code_v2(tools[0], globals=globals())\n",
    "                print(f\"工具运行结果如下：{str(result)}\\n\")\n",
    "                yield \"下载成功\"\n",
    "\n",
    "question = \"请帮我全网搜索关于智能体的最新信息，并详细分点汇总。\"\n",
    "question = \"帮我搜索3篇最新的与智能体相关的论文，详细介绍，然后下载到本地。\"\n",
    "question = \"什么是大语言模型？\"\n",
    "print(f\"问题：{question}\\n\")\n",
    "model = \"glm-4-0520\"\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "agent = AllToolsAgent(model=model)\n",
    "for char in agent.work_flow(question):\n",
    "    print(char, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"用几句话分别总结一下这十篇论文的主要内容\"\n",
    "\n",
    "for char in agent.work_flow(question):\n",
    "    print(char, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 你的任务\n",
      "根据提供的信息，回答我的问题\n",
      "\n",
      "# 你帮我找到了以下信息：\n",
      "\"\"\"\n",
      "关于智能体的搜索结果如下：\n",
      "Link: https://baike.baidu.com/item/%E6%99%BA%E8%83%BD%E4%BD%93/9446647\n",
      "智能体 目录 简介 概念的提出 定义 特性 区别内容 应用架构 社会应用 工作环境 环境定义 环境特性 组成内容 观察和感知 记忆和检索 推理和规划 行动和执行 ©2024 Baidu使用百度前必读|百科协议|隐私政策|百度百科合作平台|京ICP证030173号 京公网安备11000002000001号\n",
      "==================================================\n",
      "Link: https://new.qq.com/rain/a/20231013A03U0A00\n",
      "大语言模型时代的智能体 (I)：什么是智能体？\n",
      "==================================================\n",
      "Link: https://www.gnomic.cn/home ==================================================\n",
      "Link: https://www.wolai.com/cUCxuiNAQYJcpaYxCvR1QU ==================================================\n",
      "Link: https://blog.csdn.net/2301_81940605/article/details/136870012\n",
      "什么是智能体(agent) 智能体（Agent）是人工智能领域中的一个核心概念。在最基本的层面上，智能体可以被定义为一个实体，它能够在其所处的环境中自主地感知信息，并根据这些信息做出决策，以实现特定的目标或任务。智能体的关键特性包括自主性、感知能力和决策能力。 智能体的目标可以是简单的，如维持系统稳定，也可以是复杂的，如在多智能体系统中进行协调合作。智能体的设计和实现是为了解决特定的问题，它们可以在多种环境中运作，包括物理世界和虚拟世界。 在接下来，我们将详细探讨智能体的组成，以及它们是如何在不同的环境和应用中发挥作用的。 智能体的组成 智能体的组成是其功能实现的基础。一个典型的智能体由以下几个主要部分组成： 智能体的这些组成部分相互作用，使其能够在环境中自主地运作。感知器提供输入数据，决策制定机制处理这些数据并决定行动，执行器执行决策结果，而知识库和学习机制则不断更新和优化智能体的行为模式。 智能体类型 智能体可以根据其设计和行为模式被分类为几种不同的类型。以下是主要的智能体类型及其特点： 智能体的应用领域 智能体理论在多个领域都有广泛的应用，以下是一些主要的应用领域： 智能体的这些应用展示了它们在解决现实世界问题中的多样性和潜力。随着技术的进步，智能体在这些领域的应用将变得更加广泛和深入。 智能体和环境的交互 智能体与其环境的交互是智能体设计和功能实现的关键部分。这种交互涉及智能体如何感知环境变化，以及如何根据这些变化调整自己的行为以实现目标。以下是智能体与环境交互的几个关键方面： 感知环境： 环境建模： 行动与反馈： 适应性： 目标导向： 协作与竞争： 智能体与环境的交互是一个动态的、持续的过程，智能体必须不断地感知、决策和行动，以适应环境的变化并实现其目标。这种交互的复杂性和智能体的设计紧密相关，决定了智能体在各种应用中的性能和效果。 智能体的设计原则 设计高效智能体需要遵循一系列的原则和方法，以确保智能体能够在复杂和不确定的环境中有效工作。以下是一些关键的设计原则： 明确的目标和性能指标： 模块化和分层结构： 健壮性和容错性： 适应性和学习能力： 合理的行为选择： 交互和通信能力： 伦理和安全性： 遵循这些设计原则有助于创建能够在各种环境中可靠、有效和安全工作的智能体。智能体的设计是一个迭代和持续改进的过程，需要不断地评估、测试和优化。 多智能体框架对比 在多智能体框架和人工智能开发工具的领域中，AutoGen、CrewAI、AutoGPT、MetaGPT、WebDev、xagent 和 babyagi 都是具有不同特点和应用场景的工具。以下是这些框架和工具的对比： 在选择框架或工具时，需要考虑项目的具体需求、团队的技术背景、以及框架的社区支持和文档完善程度。不同的框架和工具有其独特的优势和局限，选择合适的工具可以大大提高开发效率和项目成功率。 挑战和未来方向 在智能体的设计和实现过程中，研究者和开发者面临着一系列的挑战，同时也在探索智能体技术的未来发展方向。以下是一些主要的挑战和未来趋势： 复杂性和不确定性的处理： 多智能体协作与竞争： 资源限制： 伦理和隐私： 安全性和鲁棒性： 增强学习和自适应能力： 人机协作： 智能物联网（IoT）： 解释性和透明度： 跨领域应用： 伦理和法规框架： 智能体技术的发展将继续推动人工智能领域的进步，同时也将带来新的挑战和机遇。设计者、研究者和政策制定者需要共同努力，以确保智能体技术的健康发展和积极影响。 如何学习大模型 AI ？ 由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。 但是具体到个人，只能说是： “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。 这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。 我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。 我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。 😝有需要的小伙伴，可以点击下方链接免费领取或者V扫描下方二维码免费领取🆓 第一阶段（10天）：初阶应用 该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。 第二阶段（30天）：高阶应用 该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。 第三阶段（30天）：模型训练 恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。 到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？ 第四阶段（20天）：商业闭环 对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。 学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。 如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。 保证100%免费 😝有需要的小伙伴，可以Vx扫描下方二维码免费领取==🆓 立减 ¥ 热门文章 最新评论 AI小白龙*:https://arxiv.org/abs/2312.10997 weixin_47301455:请问论文2是哪篇论文？ cts618:Linux服务器安装pytorch的超详细流程 AMY2134:怎么安装model mmsdk啊 Kwan的解忧杂货铺@新空间代码工作室:博主的文章总是带着深思熟虑，给予我新的学识，每篇博客都是一次心灵的洗礼，你的分享不仅教育了我，也丰富了我的内心世界。 期待你的未来更新，继续前行！ 大家在看 最新文章 目录 目录 最新文章 目录 请填写红包祝福语或标题 红包个数最小为10个 红包金额最低5元 抵扣说明： 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n",
      "==================================================\n",
      "\n",
      "搜索链接：['https://baike.baidu.com/item/%E6%99%BA%E8%83%BD%E4%BD%93/9446647', 'https://new.qq.com/rain/a/20231013A03U0A00', 'https://www.gnomic.cn/home', 'https://www.wolai.com/cUCxuiNAQYJcpaYxCvR1QU', 'https://blog.csdn.net/2301_81940605/article/details/136870012']\n",
      "关于 'agent' 的arXiv论文搜索结果 (搜索字段: all, 排序: lastUpdatedDate)：\n",
      "\n",
      "1. 标题: Pre-trained Language Models Improve the Few-shot Prompt Ability of\n",
      "  Decision Transformer\n",
      "   摘要页面: http://arxiv.org/abs/2408.01402v1\n",
      "   完整摘要: Abstract:Decision Transformer (DT) has emerged as a promising class of algorithms in offline reinforcement learning (RL) tasks, leveraging pre-collected datasets and Transformer's capability to model long sequences. Recent works have demonstrated that using parts of trajectories from training tasks as prompts in DT enhances its performance on unseen tasks, giving rise to Prompt-DT methods. However, collecting data from specific environments can be both costly and unsafe in many scenarios, leading to suboptimal performance and limited few-shot prompt abilities due to the data-hungry nature of Transformer-based models. Additionally, the limited datasets used in pre-training make it challenging for Prompt-DT type of methods to distinguish between various RL tasks through prompts alone. To address these challenges, we introduce the Language model-initialized Prompt Decision Transformer (LPDT), which leverages pre-trained language models for meta-RL tasks and fine-tunes the model using Low-rank Adaptation (LoRA). We further incorporate prompt regularization to effectively differentiate between tasks based on prompt feature representations. Our approach integrates pre-trained language model and RL tasks seamlessly. Extensive empirical studies demonstrate that initializing with a pre-trained language model significantly enhances the performance of Prompt-DT on unseen tasks compared to baseline methods.\n",
      "   发布日期: 2024-08-02\n",
      "   最后更新: 2024-08-02\n",
      "   PDF下载链接: http://arxiv.org/pdf/2408.01402v1\n",
      "\n",
      "2. 标题: \"A Good Bot Always Knows Its Limitations\": Assessing Autonomous System\n",
      "  Decision-making Competencies through Factorized Machine Self-confidence\n",
      "   摘要页面: http://arxiv.org/abs/2407.19631v2\n",
      "   完整摘要: Abstract:How can intelligent machines assess their competencies in completing tasks? This question has come into focus for autonomous systems that algorithmically reason and make decisions under uncertainty. It is argued here that machine self-confidence - a form of meta-reasoning based on self-assessments of an agent's knowledge about the state of the world and itself, as well as its ability to reason about and execute tasks - leads to many eminently computable and useful competency indicators for such agents. This paper presents a culmination of work on this concept in the form of a computational framework called Factorized Machine Self-confidence (FaMSeC), which provides a holistic engineering-focused description of factors driving an algorithmic decision-making process, including: outcome assessment, solver quality, model quality, alignment quality, and past experience. In FaMSeC, self confidence indicators are derived from hierarchical `problem-solving statistics' embedded within broad classes of probabilistic decision-making algorithms such as Markov decision processes. The problem-solving statistics are obtained by evaluating and grading probabilistic exceedance margins with respect to given competency standards, which are specified for each of the various decision-making competency factors by the informee (e.g. a non-expert user or an expert system designer). This approach allows `algorithmic goodness of fit' evaluations to be easily incorporated into the design of many kinds of autonomous agents in the form of human-interpretable competency self-assessment reports. Detailed descriptions and application examples for a Markov decision process agent show how two of the FaMSeC factors (outcome assessment and solver quality) can be computed and reported for a range of possible tasking contexts through novel use of meta-utility functions, behavior simulations, and surrogate prediction models.\n",
      "   发布日期: 2024-07-29\n",
      "   最后更新: 2024-08-02\n",
      "   PDF下载链接: http://arxiv.org/pdf/2407.19631v2\n",
      "\n",
      "3. 标题: Quantum Coding with Finite Thermodynamic Resources\n",
      "   摘要页面: http://arxiv.org/abs/2311.14561v2\n",
      "   完整摘要: Abstract:Quantum direct coding or Schumacher compression generalised the ideas of Shannon theory, gave an operational meaning to the von Neumann entropy and established the term qubit. But remembering that information processing is carried out by physical processes prompts one to wonder what thermodynamic resources are required to compress quantum information and how they constrain one's ability to perform this task. That is, if Alice and Bob only have access to thermal quantum states and clocks with finite accuracy, how well can they measure, encode and decode pure quantum state messages? In this work we examine these questions by modelling Alice's typical measurement as a unitary involving a measurement probe, investigating imperfect timekeeping on encoding and decoding and considering the role of temperature in Bob's appended qubits. In doing so, we derive fidelity bounds for this protocol involving the correlations Alice can form with their measurement probe, the variance of the clock's ticks and the temperature of Bob's qubits. Finally, we give an insight into the entropy produced by these two agents throughout the compression protocol by relating the resources they use to a quantum thermodynamic cooling protocol.\n",
      "   发布日期: 2023-11-24\n",
      "   最后更新: 2024-08-02\n",
      "   PDF下载链接: http://arxiv.org/pdf/2311.14561v2\n",
      "\n",
      "4. 标题: Coalitions of Large Language Models Increase the Robustness of AI Agents\n",
      "   摘要页面: http://arxiv.org/abs/2408.01380v1\n",
      "   完整摘要: Abstract:The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows. LLMs, whilst powerful and capable of demonstrating some emergent properties, are not logical reasoners and often struggle to perform well at all sub-tasks carried out by an AI agent to plan and execute a workflow. While existing studies tackle this lack of proficiency by generalised pretraining at a huge scale or by specialised fine-tuning for tool use, we assess if a system comprising of a coalition of pretrained LLMs, each exhibiting specialised performance at individual sub-tasks, can match the performance of single model agents. The coalition of models approach showcases its potential for building robustness and reducing the operational costs of these AI agents by leveraging traits exhibited by specific models. Our findings demonstrate that fine-tuning can be mitigated by considering a coalition of pretrained models and believe that this approach can be applied to other non-agentic systems which utilise LLMs.\n",
      "   发布日期: 2024-08-02\n",
      "   最后更新: 2024-08-02\n",
      "   PDF下载链接: http://arxiv.org/pdf/2408.01380v1\n",
      "\n",
      "5. 标题: Human foraging strategies flexibly adapt to resource distribution and\n",
      "  time constraints\n",
      "   摘要页面: http://arxiv.org/abs/2408.01350v1\n",
      "   完整摘要: Abstract:Foraging is a crucial activity, yet the extent to which humans employ flexible versus rigid strategies remains unclear. This study investigates how individuals adapt their foraging strategies in response to resource distribution and foraging time constraints. For this, we designed a video-game-like foraging task that requires participants to navigate a four-areas environment to collect coins from treasure boxes within a limited time. This task engages multiple cognitive abilities, such as navigation, learning, and memorization of treasure box locations. Findings indicate that participants adjust their foraging strategies -- encompassing both stay-or-leave decisions, such as the number of boxes opened in initial areas and behavioral aspects, such as the time to navigate from box to box -- depending on both resource distribution and foraging time. Additionally, they improved their performance over time as an effect of both enhanced navigation skills and adaptation of foraging strategies. Finally, participants' performance was initially distant from the reward-maximizing performance of optimal agents due to the learning process humans undergo; however, it approximated the optimal agent's performance towards the end of the task, without fully reaching it. These results highlight the flexibility of human foraging behavior and underscore the importance of employing optimality models and ecologically rich scenarios to study foraging.\n",
      "   发布日期: 2024-08-02\n",
      "   最后更新: 2024-08-02\n",
      "   PDF下载链接: http://arxiv.org/pdf/2408.01350v1\n",
      "\n",
      "\n",
      "[Paper(title='微波加热性能优化研究现状', authors='杨彪;杨颖;黄宏彬;韩泽民;彭飞云;钱禹东;石裕怡;吴照刚', source='昆明理工大学学报(自然科学版)', date='2024-08-05 10:12', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYBMZc4x-qVjIr4uBGeyn-Vz_n4cZqtGfYu9NCqyDW_o_1cdzyLp6elJDdQ_ecxs_kLS8-4556Kt6PSdaxkOuvloGWACUOmBzl_X-ntOfA1NEE4dqqrv48VXVJkYC7uDOrK3QT1Eq02XUgiVEM8s1-tOIGikOCkffziRiOouQgJshCPF2MuCQCAa17JAYx5mGEw=&uniplatform=NZKPT&language=CHS', abstract='微波加热是电场、磁场和热力学场相互耦合的过程，加热过程中出现的温度分布不均匀和热失控两大突出问题严重阻碍了该技术的发展。针对这两大问题，提出了微波加热性能优化研究。采用该技术，进一步改善微波加热的均匀性，提高加热效率，避免热失控的发生。本文简要阐述了现有优化微波加热性能的方法，其主要分为微波谐振腔机械结构调整优化加热性能，通过对加热腔体内的模式搅拌器、转盘、波导等进行结构调整或进行控制，从而改善腔体内的电磁场分布；最优控制优化加热性能，将最优控制方法与微波加热模型相结合，实现对加热媒质温度跟踪控制；微波参数优化改善加热性能，从微波发生器出发，对其功率、频率对加热性能的影响进行研究，结合优化算法，提升微波加热性能；多智能体协同一致性优化加热性能，将谐振腔体内的部分器件智能体化，采用一致性算法进行协同控制，优化被加热媒质的温度分布，提升加热效率。最后，对微波加热性能优化研究进行了展望。'), Paper(title='深度强化学习驱动的车联网两阶段频谱共享方案', authors='全浩宇;赵军辉;张青苗', source='无线电通信技术', date='2024-08-02 15:36', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYA7bm9WNxyHGqzxlp7zBtauMEjM5T9dS3WIQMzG_2UVYv4sYhmDBPvY0_8HMzpIVbFhurx6qpC4FjB-N0k0YE-wQ-S4fzHzfpDRMkNfSn-9-eCRFDmh7lX7zAxaVdm6HH06QkA6qZelsyXk2zNO7DhIi8-QwWHXoQVC8Ntkn3NgPc-Wxfumk00wJ1LeYy2b7l8=&uniplatform=NZKPT&language=CHS', abstract='与传统的物联网通信场景不同，车联网通信由于设备高速移动的特性面临着一系列挑战，如信道状态快速变化等。为了提升蜂窝车联网（Cellular Vehicle-to-Everything， C-V2X）通信的可靠性与有效性，提出了一种基于深度强化学习的两阶段频谱共享方案。首先，在通信时隙开始时，由宏基站根据系统状态信息将频谱资源划分给不同的车对基础设施（Vehicle-to-Infrastructure， V2I）通信链路。其次，再由车对车（Vehicle-to-Vehicle， V2V）通信链路根据本地状态信息，结合已划分的频谱资源选择合适的V2I通信链路进行复用，并实时调整设备的信号发射功率。为了优化该方案，设计了混合多智能体深度强化学习算法以提高车联网C-V2X通信系统的性能。仿真结果表明，方案能有效提高V2V通信链路的数据传输成功率，并最大化V2I通信链路的信道容量。'), Paper(title='基于大语言模型的新型电力系统生成式智能应用模式初探', authors='丁俐夫;陈颖;肖谭南;黄少伟;沈沉', source='电力系统自动化', date='2024-08-01 15:59', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYA7bm9WNxyHGqzxlp7zBtauMEjM5T9dS3UR1WI2cs54cbs-1IdZyq06qoWMdHPSPHil5Euq1KMLBTkRZa9kRF91dTy8jEq6jetiQV8lxje1pzpckGTb-29bC8ElQXTSAW4lwTH9C2klMUKlxLBWRAUV93uvDkwobaR5kyJ8Iju8mQCma3-3zoZpfM7qxv_aaG8=&uniplatform=NZKPT&language=CHS', abstract='新型电力系统数字化转型需要智能化应用体系支撑。基于此，本文探讨了新型电力系统智能应用构建的关键难题，提出了基于大语言模型的新型电力系统生成式智能应用模式及其逻辑框架，并探讨了此模式下实现智能应用全生命周期自动化构建的技术方案。针对系统仿真需求，介绍了典型生成式智能应用案例，说明了相关技术方案特点。最后，展望了生成式智能应用发展趋势和研究方向，供后续研究者借鉴。'), Paper(title='数字语义通信中基于语义重要性的量化比特分配方法', authors='朱翔本;郭彩丽;杨洋;刘传宏;莫振扬', source='北京邮电大学学报', date='2024-08-01 08:52', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCMBxHN6byUPvSAFTe5OJnkHNXitWmv70HNpmriovYSm4O2z9iztzZLaPU6PnDBncjk3jEb9g1-7WgghS9PL55uUC8hpiXMfWCI6fTngl_357aOO0Ez3toAkUiEVRbX2Mg7MIErv9WAgw-oaW6g-14U5jHaCKrvKmpOj9z-rApzH8ryhw6EKoacIbUT6wwRVc4=&uniplatform=NZKPT&language=CHS', abstract='数字语义通信在保留语义通信优势的同时能够与现有通信系统兼容，而量化是实现数字语义通信的关键。数字语义通信中的量化，需要多个量化器对多个维度的语义特征进行量化，由于硬件受限，量化总比特数有限，所以需要一种对量化器的比特分配方案。针对这一问题，提出一种基于语义重要性的比特分配算法。首先，构建了基于语义重要性的量化比特分配问题，在最大比特数的限制下，考虑不同语义信息的重要性，最小化量化和传输带来的失真；然后，引入强化学习技术，以比特分配范围为动作空间，以语义特征为状态空间，提出了基于强化学习的量化比特分配算法；最后，对所提算法进行训练，得到最优比特分配策略。仿真结果表明，所提算法收敛速度较快，在图像分类的任务场景下，所提算法的交叉熵比基准算法下降最多48.16%，分类准确度提高最多12.65%。'), Paper(title='图多智能体任务建模视角下的协作子任务行为发现', authors='李超;李文斌;高阳', source='计算机研究与发展', date='2024-08-01', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYDhpDoPKlHFeIZ5WSfwHA844MLu1bIkH1QhDeyUUuLsHogJqPFoR8RYMl2Y42lC0KepV9PwHQYFuBkOCnqlgHp1LqMKOGpo889YWGyGnkOCi0VgaQ8RbwX2FOHl5HXfQafwTane4NWQdyDOrxBoWuChgEW9_zLyO3I9KlQQqgAwf84lF4_ZDGZQ&uniplatform=NZKPT&language=CHS', abstract='大量多智能体任务都表现出近似可分解结构，其中相同交互集合中智能体间交互强度大，而不同交互集合中智能体间交互强度小.有效建模该结构并利用其来协调智能体动作选择可以提升合作型多智能体任务中多智能体强化学习算法的学习效率.然而，目前已有工作通常忽视并且无法有效实现这一目标.为解决该问题，使用动态图来建模多智能体任务中的近似可分解结构，并由此提出一种名叫协作子任务行为（coordinated subtask pattern,CSP）的新算法来增强智能体间局部以及全局协作.具体而言，CSP算法使用子任务来识别智能体间的交互集合，并利用双层策略结构来将所有智能体周期性地分配到多个子任务中.这种分配方式可以准确刻画动态图上智能体间的交互关系.基于这种子任务分配，CSP算法提出子任务内和子任务间行为约束来提升智能体间局部以及全局协作.这2种行为约束确保相同子任务内的部分智能体间可以预知彼此动作选择，同时所有智能体选择优异的联合动作来最大化整体任务性能.在星际争霸环境的多个地图上开展实验，实验结果表明CSP算法明显优于多种对比算法，验证了所提算法可以实现智能体间的高效协作.'), Paper(title='计算社会科学：学科体系与领域演进', authors='吕鹏', source='求索', date='2024-07-31 17:08', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCkGx2s-rn8icNxf-Q3TD5p24mHHAUHVW4MbyOqOhY6RvqnI5jUJj8ppwVp7U0oGsy_9oCCnuGQh8raRehqV6epRfHVWW9lkx48JKuyDg6_peQyOpEk3OiHIc868kXXDBtb93pEgAOaMfwIaYf79IrCasnu8Py62uP3qjlHvdwSafxMBZPfqdw7bTqXARAqiDQ=&uniplatform=NZKPT&language=CHS', abstract='当前，计算社会科学处在深度发展阶段，需要做出阶段性梳理与总结，以促进学术共同体的稳健发展。计算社会科学的学科使命在于通过参与范式革命，推动理论创新，实现方法升级迭代，最终完成传统研究边界的拓展。计算社会科学的学科体系与分支领域的发展现状与趋势，可基于“总论+分论”框架进行梳理。总论与分论之间的关系，呈现“松散联合体”特征。计算社会科学的整体性推进和发展，主要依赖于各分支领域的自主探索与发展交织。整体性的理论体系、方法体系、学科体系，构成计算社会科学总论的主体内容。各分支领域的发展，构成分论的主要内容，形成了具有众多相对自主的理论导向、方法应用、发展阶段、研究主题等。计算社会科学相关分支领域在自主、平行发展的同时，也在理论基础、研究方法、学科议题方面存在着彼此交织、借鉴和强化的关系。这些合力，可能促使传统社会科学的边界逐渐模糊化，并孕育和催生新的整体性学科，即计算社会科学。计算社会科学的整体性涌现过程还面临多重挑战和机遇，持续推进相关的理论发展、学科融合与方法整合，是推动计算社会科学向更高水平发展的题中应有之义。'), Paper(title='机会式群智感知中覆盖最大化的去中心化任务分配', authors='陈杨辉;於志勇;黄昉菀;郝勇涛;涂淳钰;吴越钟', source='小型微型计算机系统', date='2024-07-31 15:14', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYBjxtDT3t-0xe0wvKG9Of6heNSDAqsE7IdwuYnzs7Q8hBF1Ue5w4ntTOa2WFxc9fgArNYRDELyghp4HQ_5UGVdXMbq8T6UWio016lUPjd5B8twVzSSKV8DEvLP32405U2CC1lawtD1ACW5qV17E2yj_nEVI3sPbxGvSmaQZj8dtxQ92mDmy6ITsX4rWM2lxd7k=&uniplatform=NZKPT&language=CHS', abstract='传统的机会式群智感知需要由平台进行集中式任务分配，存在对平台性能要求高和隐私泄露等问题。为了解决这些问题，本文提出了一种新颖的方案，旨在去中心化的机会式感知场景下，实现带有全局预算约束的任务分配，使任务覆盖最大化。区别于传统方法，通过参与者自主选择是否参与感知任务的方式来实现任务分配，构造了一个多智能体协同系统。在去中心化场景下，保证全局约束并实现高效的任务分配是一大挑战。为解决上述挑战，提出了两种方法：一种是将蚁群算法应用到任务分配问题上，同时以通信的方式获取目标评估函数以及更新信息素，实现智能体间协同求解，从而适用于去中心化的场景；另一种是基于QMIX框架的决策通信方法，将QMIX中智能体网络的输出作为建议动作，引入决策通信层，根据建议动作以及动作价值进行协商，从而遵循全局约束条件。在真实数据集上的实验结果表明，本文提出的两种方法在任务覆盖率上可以与集中式规划方法相当，并在耗时等综合性能上具有良好的表现。'), Paper(title='人工智能体价值对齐的分布式路径探赜', authors='闫坤如', source='上海师范大学学报(哲学社会科学版)', date='2024-07-31 14:53', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYDu_2nO7dYusy4gaI8_bdcIHqk4oDgYSwx0Rq5pXcF8iUwLNK646ZYNOohYd6-UhOPKAre13826LZ76hlC4zL06g_iYSyavI_fywEyNfxJJSXBHhLdYHjrN-oDg49dHplrOohzoVRi-PT4a0u_c8BkEKq5HPoyED6O6TiM6jHKyyrSaLtRAZdbbmhHKBBFLAxA=&uniplatform=NZKPT&language=CHS', abstract='人工智能体价值对齐，源于人类的有限理性、人工智能体的自主性、不确定性和风险性。价值对齐需要在考察人工智能体的道德属性与调节作用的基础上，分析其必要性和可能性。为了实现人工智能价值对齐的目标，需要妥善处理好伦理共识与多元价值观、抽象价值规则与具体人工智能技术应用场景、人类终极伦理目标与短期价值追求之间的关系。在此基础上，应为人工智能体的研发设定基本的道德准则和伦理底线，明确人工智能体的设计边界，确保其不对人类的价值和权利造成干扰和伤害，避免AI系统偏离人类价值观，以引导和规范人工智能技术的发展方向。'), Paper(title='人工智能与灵魂：超越科技的哲学追问——基于概念建构主义视角', authors='甘莅豪', source='上海师范大学学报(哲学社会科学版)', date='2024-07-31 14:41', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYDu_2nO7dYusy4gaI8_bdcIHqk4oDgYSwx0Rq5pXcF8iUwLNK646ZYNhLpeh8ReZyMlzQljpVwiHgGx0K8bVsHcQO6njbGneOD9adARbTXp2crwKAiDK-tGT2FWhLbBxq809ebUNaZYjOmLNalSeaE2Fn51I8gZdsHImwNfynb3c8lG801Hl4zpNBUEBsvFhac=&uniplatform=NZKPT&language=CHS', abstract='在探讨人工智能与灵魂的关系时，概念建构主义视角为人们提供了一种深入的理解方式。当前弱人工智能并未被赋予、也不需要灵魂。然而，随着技术的不断进步，强人工智能的到来可能引发对灵魂概念的重新思考。在这一新的时代背景下，灵魂可以被重新定义为数据、计算和交互的集合，并建构所谓的“灵魂智格”。同时，对“轮回说”“中介说”等灵魂概念的话语重设也为人们提供了新的视角。这些变化不仅将影响人们对人工智能本质的理解，也将引发对其在后人类社会中角色定位的新思考。更重要的是，这种新的概念建构还将对人工智能的伦理和道德责任产生深远影响，为未来的科技发展提供新的道德和伦理参考。从概念建构主义的视角来看，人工智能与灵魂的关系是一个动态发展的过程，随着技术的进步和时代的变迁，这一关系可以不断被重新定义和解读。'), Paper(title='基于深度强化学习的分层自适应PID控制算法', authors='余文浩;齐立哲;梁瀚文;孙云权', source='计算机系统应用', date='2024-07-31 11:33', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYAIa6TB2NwHhZZEb-cibKOh76OgdbbZzRz6VBBN8m5ByaoZbTKeyAMiU5N_erhSKrMafb2KwALsFBB1HArK2KenQg8vpGM4_CZHjOHOn6PQoz85DydkkxG74i2FWozAAMwPEeS-Y6G-_mshKFoTQs3OEaQqbmjG0JEoN2S6B88Dr6R1ww8YrRQ-gklHnPauV5Q=&uniplatform=NZKPT&language=CHS', abstract='比例积分微分(PID)控制在工业控制和机器人控制领域应用非常广泛.然而,其在实际应用中存在参数整定复杂、系统无法精准建模以及对被控对象变化敏感的问题.为了解决这些问题,本文提出了一种基于深度强化学习算法的分层自适应PID控制算法,即TD3-PID,用于移动机器人的自动控制.其中,上层控制器通过实时观测当前环境状态和系统状态实现对下层PID控制器参数和输出补偿量进行调整,以实时补偿误差从而优化系统性能.本文将所提出的TD3-PID控制器应用于4轮移动机器人轨迹跟踪任务并和其他控制方法进行了真实场景实验对比.结果显示TD3-PID控制器表现出更优越的动态响应性能和抗干扰能力,整体响应误差显著减小,在提高控制系统性能方面具有显著的优势.'), Paper(title='基于Anylogic的云制造平台-企业协同调度仿真系统', authors='王琳煊;刘永奎;张霖;林廷宇;王力翚', source='系统仿真学报', date='2024-07-31 10:35', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCdThoBZxhlLgFkaR3OSPKOHIg_-mEX0drJ-H7R88LoQGsnKBuYtON-BrLDj5130q2AQfOjhcHXqIw1URCg5zt_ObjbLRJdG8zOSgX399G4aEbnqzbPibP0jDLrFKr5e6Tsmrm5gP1bHBhdoorou_1Gj51W5Kgm7aF8P5pleMTuEqh7qT4A9KhcYx_cf1DC6E0=&uniplatform=NZKPT&language=CHS', abstract='针对当前云制造平台与企业协同调度问题研究不足，以及缺乏相关仿真系统对调度策略组合进行可视化仿真等问题，设计并开发了一个支持云制造平台-企业协同调度动态过程可视化的仿真系统。首先，详细分析了系统多方面需求，并在此基础上提出了一个基于层次型多智能体的可扩展的平台-企业协同调度模型及系统功能架构；其次，结合工业机器人供应链案例，考虑云制造平台层随机选择、时间最优策略以及企业层FIFO (First In First Out)、SPT (Shortest Processing Time)、EDD (Earliest Due Date)等策略组合，构建了平台-企业协同调度仿真模型。最后，基于Anylogic进行了系统实现，并通过多组策略组合与用例开展了仿真实验。结果表明，该系统具有制造场景可扩展、仿真过程可视化等功能特点，同时能够对平台层和企业层调度策略组合的性能进行仿真、测试及优化，从而为云制造平台-企业协同调度策略提供了一个仿真环境和验证平台。'), Paper(title='多智能体系统固定时间一致性的多永磁同步电机转速协同控制', authors='侯利民;兰骁儒;赵世杰;李政龙', source='电工技术学报', date='2024-07-31 09:31', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYBPFb9yJkrLNOSbiUdVpkNCZYWEdlwK49284-Pn_RVfz2bGhC3VgIaKLpN-Ml2kiPRv8zqXFcaKHPbkmAxhIYn1umo8A4QaNh5DjERNoLz_XtD2DB9o8DQJn1cHSMeKAX9DGa1rz3G709GjtAG3nWJYMePiurzCY8T-qWoXjfSzzjofAf9eBA9X8ymPAI1gbcs=&uniplatform=NZKPT&language=CHS', abstract='为了提高多电机转速协同控制精度，提出了一种多智能体系统固定时间一致性的多永磁同步电机转速协同控制新思想。首先，将多永磁同步电机调速系统视为一个多智能体系统，设计了基于无向通信拓扑图的固定时间一致性协议。同时，设计了固定时间滑模观测器估计扰动并在一致性协议中引入前馈补偿，从而得到期望的q轴电流。然后，在矢量控制调速系统的框架下设计了固定时间互补滑模电流控制器，用于跟踪q轴参考电流。利用李雅普诺夫函数分别证明了控制器和观测器可以在与系统初始状态无关的情况下实现固定时间内收敛。最后，在三台永磁同步电机调速系统实验平台上与传统偏差耦合控制算法进行了对比实验验证，证明了所提控制算法的可行性和鲁棒性。'), Paper(title='移动边缘计算中分布式智能服务缓存和资源分配联合优化', authors='王翔', source='重庆理工大学学报(自然科学)', date='2024-07-31 07:10', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYAeCRDPbs7LRhhtMgHdDwcjJ_TxVvFPC3tQewuEUZ1jOWb-oHCjycB2N89XZI53qmCoSCdnE_-TdVyTRdbLq-nxGIFqmIEIao_sV7Lhopkb7VQv9C9KWyK2CK5wCy7p6G0lgLO7QIDYUZORIXpb7pWiG_Zq0WZ5XG_bOjymTUoYL2qjZ0-Q5T68tn2mX1GEObU=&uniplatform=NZKPT&language=CHS', abstract='随着通信技术和物联网技术深度融合，边缘网络结构日益密集化、异构化。同时，在边缘网络环境中，广域差异化业务、去中心化算网资源部署以及高度动态化网络环境等特征，制约了网络服务缓存和资源分配的效率。针对上述问题，对去中心化的边缘网络场景下的任务卸载、服务缓存和资源联合优化展开研究。首先，研究并建立了服务缓存和任务卸载模型。其次，以最小化任务的处理成本为目标，将服务缓存、算力资源分配和传输功率控制的联合优化问题抽象为部分可观测马尔科夫决策过程。然后，针对模型集中训练存在的隐私泄露问题，设计了一种基于联邦学习的分布式模型训练方法，进而提出了一种基于联邦多智能体深度强化学习的分布式服务缓存和资源分配算法来自主决策服务缓存、算力资源分配和传输功率控制决策。此外，考虑到本地模型的差异性，在进行参数聚合时，使用注意力机制，为本地模型分配不同的权重。最后，仿真验证了所提算法在任务处理成本、缓存命中率方面有明显性能提升。'), Paper(title='基于动态多步损失厌恶的在线投资组合管理策略', authors='马聪;陈怡君', source='工程数学学报', date='2024-07-31', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCKc9MTw7gfiLi9g4UVAWqE6DMcrIUbDMHPmc6aAs4gzE4pMDJT1HUx0ZBK_z7G8eN_cupAj2F1VacRIXs6OqlB1_2ckcd17vVn1swbFmt1oVC3glOEfWnmb62lC3ksblToi86KZItH9uTLWxPWQvDjPrnbj0RMf2z7eCxc7qkNC9JgiKo28wq0&uniplatform=NZKPT&language=CHS', abstract='奖励函数设计的合理性对于提升深度强化学习算法的性能至关重要。针对投资组合管理任务，识别并解决了现有奖励函数的两大缺陷：一是过度关注短期市场波动而忽略长期趋势；二是对带来奖励和造成损失行为的奖惩相当，这并不符合投资者的损失厌恶心理。为此，借鉴行为金融学中的投资者损失厌恶理论，创新性地提出了一种多步损失厌恶(Multi-step Loss Aversion, MSLA)奖励函数，以更准确地刻画投资者在交易中的行为模式，并据此构建了在线投资组合管理策略。选取A股市场上三个具有代表性的指数，构建了相应的投资组合，在2019年至2023年的历史数据上进行了回测实验。实验结果表明，MSLA奖励函数显著提升了策略的整体性能，从累计收益率、夏普比率和最大回撤等指标来看，普遍优于现有的其他算法。此外，该策略不仅适用于不同市值大小股票组成的投资组合，而且在上涨、下跌和震荡的市场状态下均能保持稳健的性能，这充分说明了该算法在投资组合管理中的有效性和实用性。'), Paper(title='面向数字孪生的混合业务确定性传输调度机制', authors='王克文;张维庭;廖培希', source='计算机科学', date='2024-07-30 16:44', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCKc9MTw7gfiLi9g4UVAWqE1vFVQSwzSzYOgzuI1DjygMyp50Z3_d_6nLmGkNxXrwv0bF_99Ml97icD2ygjOJVhv6b5Yu3SSA8zZwi2_FYj2yhcQW5DCDE9pMxeCv837VnDFd8rclZ0IMccpNy3XsLRlM627Sfdx0Vi8vEQ28JJ7Yt0QlTkH0fDpFNIKghYuok=&uniplatform=NZKPT&language=CHS', abstract='针对铁路运维场景中混合业务流的端到端传输，提出了数字孪生架构下基于深度强化学习的确定性传输调度机制，即在线混合业务流端到端传输调度机制（End-to-End Transmission Scheduling Mechanism for Online Mixed-traffic，E2ETSM-OMT）。该机制基于差异化调度策略的思想，将业务流分为监控与数据采集流、控制与执行业务流和数据分析与业务优化流三类，通过确定性技术实现跨域端到端低时延传输。进一步地，通过模型映射和行为映射将物理空间全方位高精度投到虚拟空间，在数字孪生网络构建混合业务的拓扑结构，预先分配数据传输路径和时隙资源，从而减少不同业务流之间的调度冲突和资源竞争。同时，通过深度强化学习（Deep Reinforcement Learning，DRL）智能体在线决策，兼顾效果与效率，对不同收益的业务流进行调度。与已有机制相比，数字孪生技术可以实现物理世界与虚拟世界相互映射，实现非平稳通信环境下DRL的应用，避免在现实网络中探索造成的服务质量损失。仿真结果表明：所述面向数字孪生的确定性传输调度机制在保障成功调度混合业务流的同时，以较...'), Paper(title='基于状态反馈和输出反馈的离散线性多智能体系统的二分一致性研究', authors='姚瑶;张捷;王健安;李晓磊;李志强', source='控制与决策', date='2024-07-30 16:38', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYAQD0vdOM9EIG3z9-BDugLExcJTAUovrnP0PP8WwU7VOT7Q2DgzV3qvI0no2PsOQMfBWOBbh7rLQBhnM_VtuMZGt0wyDgHLQtPHg8S-dEI9vOEZNT8kMFekPEpA90RJ38gZBCWAWa7Yfa0q7DNm7poKrf2CRn3qgE3U9E_XZYDoH9G5eOdugz5MFv-chZTHLio=&uniplatform=NZKPT&language=CHS', abstract='基于状态反馈和输出反馈控制方法,解决离散线性领导-跟随多智能体系统的二分状态一致性跟踪控制问题.其中,领导者具有离散自治动态并能够产生理想参考轨迹信号.首先,基于盖尔圆盘定理和离散代数黎卡提方程提出一种新型分布式状态反馈控制协议.其中,基于系统拓扑矩阵设计的控制耦合增益能够使得全局跟踪误差系统包含在单位圆的稳定域内.在结构平衡条件下,通过Lyapunov稳定性理论和分离原理可证明符号有向图下两个对立子组的智能体可实现二分状态一致.然后,基于邻居合作-竞争交互信息引入新型分布式状态观测器以实现跟随者状态的跟踪.进而提出一类基于观测器的输出反馈二分控制协议,在状态不可获知情况下可实现理想的领导-跟随二分状态跟踪,也可应用于更一般的传统一致性控制场景.最后,给出两个仿真算例验证所提算法的可行性和有效性.'), Paper(title='基于语言推理与认知记忆的自动驾驶决策模型', authors='王祥;谭国真;彭衍飞;任浩;李健平', source='吉林大学学报(工学版)', date='2024-07-30 15:23', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYAMoMaZhXI52d6gfGPEook5_U4rsIK-ZJ4y6fRUC-znSemwEzeKlMnyoPutCNAVTStjJ1cbbZWZEz-cnOh_idOcDSaWcb2cI12-xTiVhZbNAdylX77RNcz7k0o_HrkOKPBOlwa2IVuZHpW8VyB4Vqyu9LHs9t6ySBCG8eDgUCuf56Ovd9Rs4FESuwgak_cH5CA=&uniplatform=NZKPT&language=CHS', abstract='针对传统自动驾驶安全性能和学习效率低下等问题，提出了一种可持续学习和理解语言信息的自动驾驶安全决策模型。参考人类驾驶过程中推理决策和经验积累的过程，利用大型语言模型(Large Language Model，LLM)作为决策智能体将思维链推理、两阶段注意力机制和认知记忆存储与检索整合到驾驶过程上下文安全学习中，利用运动学模块将LLM决策转化为可操作的驾驶命令，实现对安全驾驶经验的持续学习。实验结果表明：提出的决策模型相对于基于规则、强化学习和知识的方法在安全效率方面有显著提升，并具备持续学习和根据人类指令变化驾驶行为的能力，为类人自动驾驶提供参考。'), Paper(title='基于深度强化学习的边缘计算实时比例任务卸载', authors='张圣;李君;胡静;徐钰龙', source='计算机应用与软件', date='2024-07-30 12:07', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYD8W4oab-bwZwOtrw76hDPa1gnVVAqdcZy3C7nLkq_7RxTzDxiWlY_ioobFY-VBa75TKSgoAqdVIRaaDarkYijXhf3lC4UdKIndTyDNVWMMDyjFKDStU5F21qhfgDKKoZFUs9Si_BH-XOv3bNr9ULONcBnXocf8z0NFE9IwH6HyDrnKrcut_ozyoxKr5CdG0Bc=&uniplatform=NZKPT&language=CHS', abstract='在移动边缘计算系统中，边缘节点会因为大量任务的到来产生高负载。移动用户如何做出合适的任务卸载决策是必须解决的难题。针对该问题，建立了一种具有时变带宽的异构卸载场景，对于每个应用程序，移动用户需要确定任务卸载比例。将上述问题形式化为一个长期优化问题，设计了一个基于深度强化学习的算法来解决该问题。为了改进算法对长期代价的估计，模型结合了长短期记忆(Long Short Term Memory，LSTM)技术、多智能体深度确定性策略梯度（Multi-Agent Deep Deterministic Policy Gradient，MADDPG）算法，通过增加优先经验回放机制（Prioritized Experience Replay，PER），提高了样本的利用率。实验结果表明，所提出的算法性能提升了17%。'), Paper(title='动态事件触发下的一阶非线性多智能体系统设定时间一致性', authors='石井龙;刘志杰;郭皓晨;刘剑', source='工程科学学报', date='2024-07-30 10:52', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYBWVIZX-logSAgA8NUZTLb9DXMX2HFGj5fFtre_RPX7JaGRuX6hMF_PXTSNwGxsAadj-u0A6Y3Zp0nwk9rb5qe7juVj3tECKi8wGJ2om-2v23f3ILClyqRc-PTEpcK5tEmkdnf2G5HeVTZJP1u4RtZ9l6h9QEZFIXZenJzrSR9317s2fviZwuIS&uniplatform=NZKPT&language=CHS', abstract='为了保证多智能体系统收敛速度快的同时节约通信资源，针对一阶非线性多智能体系统提出了动态事件触发设定时间一致性算法.相较于传统的有限时间和固定时间控制算法，设定时间控制算法引入时变函数，可以保证系统在任意预设时间内均可达到一致性.同时，设定时间控制算法的收敛时间上界不依赖于系统初始状态、拓扑结构和控制参数，可以根据用户需求任意提前设置.故设定时间控制算法解决了计算冗杂的问题，同时可以保证控制精度.为了进一步减少触发次数，在现有的静态事件触发控制算法的基础上引入新的动态变量，进而设计出动态事件触发算法.动态变量随时间改变，可以降低触发次数，从而减少控制器更新频率和执行机构的磨损程度.鉴于非线性系统广泛存在于实际应用场景中，基于非线性系统设计的控制算法更具有一般性.最后，通过数值仿真验证动态事件触发设定时间一致性算法的有效性.综上，本文所提出的动态事件触发设定时间一致性算法可以保证一阶非线性系统在任意设定时间内实现一致性，并且减少触发次数，更可能应用于实际工程.'), Paper(title='基于大语言模型的新型电力系统用户特性立体应用模式初探', authors='余涛;王艺澎;罗庆全;蔡新雷;刘熙鹏;梁敏航', source='高电压技术', date='2024-07-29', link='https://kns.cnki.net/kcms2/article/abstract?v=hyVvMdIOuYCOcaBD9ij94tUcI4Gr_W5TsN0jIiq2z470UEj5vphgBz-MKNsy00EjEk4shVYpfICFjHiyqV-vJEOeZ39nzZGGiZn8OFjGHCUJVXuXeJ-EXIG9mTUI1vCddHh5TyuLbkJRU0rgCKJiKnzzvDAQz6pfIZab4f0cbHU6y_yolT2UleY-5FolqxMs&uniplatform=NZKPT&language=CHS', abstract='随着新型负荷的广泛接入与虚拟电厂建设的不断推进，新型电力系统中多元的负荷结构与频繁的网荷交互使得用户特性应用在数据融合、特性挖掘和业务赋能面临关键挑战。因此，该文首先深入分析了用户特性的研究现状，以此为基础提出了新型电力系统用户特性立体应用模式，贯通了“多源数据-多维特性-多元模块-多样业务”的应用链路。然后，针对该模式实践中海量多源数据可用性差、特性刻画灵活性低、业务贯通复杂性高的核心技术难题，立足于近期大语言模型备受关注的显著能力与智能体应用范式，分别在自适应数据治理、对话式数据交互、自动数据分析与机器学习、多智能体应用系统架构方面提出了解决方案。进一步，更通过用电数据库交互与业扩报装接入优化的案例表明所提方案能够自动化、智能化、个性化地开展用户特性应用，有望在实际中应对用户侧业务面临的关键挑战。最后，对大语言模型赋能用户侧海量资源管控以及系统智能水平跃升进行了展望。')]\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "现在，请回答我的问题：\n",
      "\"\"\"\n",
      "请帮我全网搜索关于智能体的最新信息，并详细分点汇总。\n",
      "\"\"\"\n",
      "\n",
      "# 你的工作流\n",
      "1. 你必须首先详细回答我上述的问题，不需要担心token限制，并且你必须以类似如下的格式回答我的问题：\n",
      "\"根据我找到的信息，我认为......\"\n",
      "2. 然后在最后简要列举你搜索到的所有信息+链接，作为参考\n",
      "\n",
      "# 参考输出\n",
      "根据我找到的信息...\n",
      "\n",
      "# 相关链接\n",
      "- [链接1](https://...)\n",
      "...\n",
      "\n",
      "# 注意\n",
      "- 相关链接只需要在第二步展示即可，第一步不需要提供链接\n",
      "\n",
      "现在，请回答我的问题：\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent_conversations[-2:-1][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from growing_agent_tools.search_cnki import *\n",
    "keyword = \"智能体\"\n",
    "num_pages = 1\n",
    "use_proxy = False\n",
    "proxy = None\n",
    "\n",
    "results_matrix = search_cnki(keyword, num_pages, use_proxy, proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
