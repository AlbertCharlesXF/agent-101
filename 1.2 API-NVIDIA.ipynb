{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta/llama3-70b\n",
    "# key: https://build.nvidia.com/explore/discover\n",
    "\n",
    "mykey = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an example of how you can build an LSTM (Long Short-Term Memory) model in Keras to predict stock prices:\n",
      "```\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from keras.models import Sequential\n",
      "from keras.layers import LSTM, Dense\n",
      "\n",
      "# Load stock price data\n",
      "df = pd.read_csv('stock_prices.csv', index_col='Date', parse_dates=['Date'])\n",
      "\n",
      "# Convert data to numpy array\n",
      "data = df['Close'].values.reshape(-1, 1)\n",
      "\n",
      "# Scale data using Min-Max Scaler\n",
      "scaler = MinMaxScaler()\n",
      "data_scaled = scaler.fit_transform(data)\n",
      "\n",
      "# Split data into training and testing sets\n",
      "train_size = int(0.8 * len(data_scaled))\n",
      "test_size = len(data_scaled) - train_size\n",
      "train_data, test_data = data_scaled[0:train_size], data_scaled[train_size:len(data_scaled)]\n",
      "\n",
      "# Create training and testing datasets\n",
      "def create_dataset(dataset, look_back=1):\n",
      "    X, Y = [], []\n",
      "    for i in range(len(dataset)-look_back-1):\n",
      "        X.append(dataset[i:(i+look_back), 0])\n",
      "        Y.append(dataset[(i+look_back), 0])\n",
      "    return np.array(X), np.array(Y)\n",
      "\n",
      "look_back = 30\n",
      "train_X, train_Y = create_dataset(train_data, look_back)\n",
      "test_X, test_Y = create_dataset(test_data, look_back)\n",
      "\n",
      "# Reshape data for LSTM\n",
      "train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
      "test_X = test_X.reshape(test_X.shape[0], 1, test_X.shape[1])\n",
      "\n",
      "# Create LSTM model\n",
      "model = Sequential()\n",
      "model.add(LSTM(units=50, return_sequences=True, input_shape=(train_X.shape[1], 1)))\n",
      "model.add(LSTM(units=50, return_sequences=False))\n",
      "model.add(Dense(units=1))\n",
      "model.compile(loss='mean_squared_error', optimizer='adam')\n",
      "\n",
      "# Train the model\n",
      "model.fit(train_X, train_Y, epochs=50, batch_size=1, verbose=2)\n",
      "\n",
      "# Make predictions on test data\n",
      "predictions = model.predict(test_X)\n",
      "\n",
      "# Evaluate the model\n",
      "mse = model.evaluate(test_X, test_Y)\n",
      "print(f'MSE: {mse}')\n",
      "\n",
      "# Plot the predicted prices\n",
      "import matplotlib.pyplot as plt\n",
      "plt.plot(test_Y, label='Actual')\n",
      "plt.plot(predictions, label='Predicted')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "```\n",
      "Here's what's happening in the code:\n",
      "\n",
      "1. We load the stock price data from a CSV file into a Pandas dataframe.\n",
      "2. We convert the data to a numpy array and scale it using the Min-Max Scaler.\n",
      "3. We split the data into training and testing sets.\n",
      "4. We create a function `create_dataset` to create the training and testing datasets. This function takes in the dataset and a `look_back` parameter, which determines how many previous time steps to use as input.\n",
      "5. We reshape the data for the LSTM layer.\n",
      "6. We create an LSTM model with two layers: the first layer has 50 units and returns sequences, while the second layer has 50 units and does not return sequences. The output layer is a dense layer with one unit.\n",
      "7. We compile the model with the mean squared error loss function and the Adam optimizer.\n",
      "8. We train the model on the training data for 50 epochs with a batch size of 1.\n",
      "9. We make predictions on the test data and evaluate the model using the mean squared error.\n",
      "10. We plot the predicted prices against the actual prices.\n",
      "\n",
      "Note that this is just an example, and you may need to adjust the hyperparameters (e.g. number of units, number of layers, epochs, batch size) to improve the performance of the model. Additionally, you may want to experiment with different architectures, such as using convolutional layers or attention mechanisms, to improve the model's performance.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      " 以下是上述代码中可以优化的地方：\n",
      "\n",
      "1. 数据规模：如果数据规模较大，可以考虑使用GPU加速计算。\n",
      "2. 数据预处理：可以尝试使用其他标准化方法，如标准化（StandardScaler）或规范化（Normalizer），以获得更好的预测结果。\n",
      "3. 模型参数：可以尝试调整LSTM模型的参数，如单元数量、层数、学习率等，以获得更好的预测结果。\n",
      "4. 训练时间：可以尝试使用不同的优化器，如SGD、RMSprop等，以缩短训练时间。\n",
      "5. 过拟合：可以尝试使用Dropout、L1/L2正则化等技术，以防止过拟合。\n",
      "\n",
      "以下是优化后的代码：\n",
      "```\n",
      "# 导入必要的库\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from keras.models import Sequential\n",
      "from keras.layers import LSTM, Dropout, Dense\n",
      "from keras.optimizers import SGD\n",
      "\n",
      "# 加载股票价格数据\n",
      "df = pd.read_csv('stock_prices.csv', index_col='Date', parse_dates=['Date'])\n",
      "\n",
      "# 将数据转换为numpy数组\n",
      "data = df['Close'].values.reshape(-1, 1)\n",
      "\n",
      "# 标准化数据\n",
      "scaler = StandardScaler()\n",
      "data_scaled = scaler.fit_transform(data)\n",
      "\n",
      "# 将数据分为训练集和测试集\n",
      "train_size = int(0.8 * len(data_scaled))\n",
      "test_size = len(data_scaled) - train_size\n",
      "train_data, test_data = data_scaled[0:train_size], data_scaled[train_size:len(data_scaled)]\n",
      "\n",
      "# 创建训练和测试数据集\n",
      "look_back = 30\n",
      "train_X, train_Y = create_dataset(train_data, look_back)\n",
      "test_X, test_Y = create_dataset(test_data, look_back)\n",
      "\n",
      "# 调整数据形状以适应LSTM模型\n",
      "train_X = train_X.reshape(train_X.shape[0], 1, train_X.shape[1])\n",
      "test_X = test_X.reshape(test_X.shape[0], 1, test_X.shape[1])\n",
      "\n",
      "# 创建LSTM模型\n",
      "model = Sequential()\n",
      "model.add(LSTM(units=50, return_sequences=True, input_shape=(train_X.shape[1], 1)))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(LSTM(units=50, return_sequences=False))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(units=1))\n",
      "\n",
      "# 编译模型\n",
      "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01))\n",
      "\n",
      "# 训练模型\n",
      "model.fit(train_X, train_Y, epochs=50, batch_size=32, verbose=2)\n",
      "\n",
      "# 预测测试数据\n",
      "predictions = model.predict(test_X)\n",
      "\n",
      "# 评估模型\n",
      "mse = model.evaluate(test_X, test_Y)\n",
      "print(f'MSE: {mse}')\n",
      "\n",
      "# 绘制预测结果\n",
      "import matplotlib.pyplot as plt\n",
      "plt.plot(test_Y, label='Actual')\n",
      "plt.plot(predictions, label='Predicted')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "```\n",
      "在优化后的代码中，我们使用了以下技术：\n",
      "\n",
      "1. 使用GPU加速计算：在Keras中，可以使用`tensorflow-gpu`包来使用GPU加速计算。\n",
      "2. 使用标准化数据：我们使用`StandardScaler`将数据标准化，以获得更"
     ]
    }
   ],
   "source": [
    "# 文本生成\n",
    "from openai import OpenAI\n",
    "\n",
    "model = \"mistralai/mistral-large\"\n",
    "model = \"microsoft/phi-3-mini-128k-instruct\"\n",
    "model = \"meta/llama3-70b-instruct\"\n",
    "model = \"mistralai/mixtral-8x22b-instruct-v0.1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey  \n",
    ")\n",
    "\n",
    "question = \"请帮我构建一个LSTM模型，用于预测股票价格。请用中文回答。\"\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":question}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta/llama3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "ans = \"\"\n",
    "for chunk in completion:\n",
    "    char = chunk.choices[0].delta.content\n",
    "    ans += char\n",
    "    if char is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\":\"assistant\",\"content\":ans}) # 增加AI的回复\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*100 + \"\\n\\n\")\n",
    "\n",
    "question_2 = \"请找到上述代码可以优化的地方，分点列举，然后给出优化后的代码。请用中文回答。\"\n",
    "\n",
    "messages.append({\"role\":\"user\",\"content\":question_2}) # 增加用户的问题\n",
    "\n",
    "# 生成新的回复\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "ans = \"\"\n",
    "for chunk in completion:\n",
    "    char = chunk.choices[0].delta.content\n",
    "    ans += char\n",
    "    if char is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保持一星火种，激发万丈豪情。"
     ]
    }
   ],
   "source": [
    "# 多轮对话\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey  \n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta/llama3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请你帮我将这个句子翻译为中文：keep a single spark to start a prairie fire\"},  # user代表用户，content为用户提问的内容\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一个火花来点燃草原之火\"},  # assistant代表glm4，content为glm4的回答\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译为更加优雅的句子。\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一星火种，点燃草原烈焰。\"},\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译成一句对偶句。\"}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    "    )\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### microsoft/phi-3-mini-128k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "土星是太阳系中的第八颗行星，以其独特的环系统而闻名。土星的平均半径大约为76,950千米，这意味着它的大小约为11.2地球半径。土星的主要组成部分是氢氧化钾，这是行星中最大的气体。土星的环系统是由巨大的冰块组成的，这些冰块被围绕土星运动，形成了一系列的环。\n",
      "\n",
      "\n",
      "土星的环系统是太阳系中最丰富的，据统计，土星有超过10000个环。这些环系统是由冰块、岩石和氦气组成的，它们在土星的引力下形成。土星的环系统具有很高的密度，这使得它们比地球的卫星更加密集。\n",
      "\n",
      "\n",
      "土星还有一个非常独特的天文现象，即土星的轨道偏离了其他行星的轨道。这种偏离是因为土星的巨大环系统对其运动产生了重力影响。此外，土星还有一个被称为“红星”的天文现象，这是由于土星的环系统中含有的氦气在太阳黑暗时分带着红色光。\n",
      "\n",
      "\n",
      "总之，土星不仅因其巨大的半径而著名，而且因其独特的环系统和其他天文现象，它是太阳系中最具吸引力的行星之一。"
     ]
    }
   ],
   "source": [
    "# 文本生成\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/phi-3-mini-128k-instruct\",\n",
    "        messages=[{\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"我对太阳系的行星非常感兴趣，特别是土星。请你使用中文提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"\n",
    "            }],\n",
    "    temperature=0.2,\n",
    "    top_p=0.7,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一闪烁的星火，草原烈焰点燃。"
     ]
    }
   ],
   "source": [
    "# 多轮对话\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/phi-3-mini-128k-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请你帮我将这个句子翻译为中文：keep a single spark to start a prairie fire\"},  # user代表用户，content为用户提问的内容\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一个火花来点燃草原之火\"},  # assistant代表glm4，content为glm4的回答\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译为更加优雅的句子。\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一星火种，点燃草原烈焰。\"},\n",
    "        # {\"role\": \"user\", \"content\": \"请你翻译成一句对偶句，即两个长度一致分句。\"}\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译成一句对偶句。\"}\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    top_p=0.7,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mistralai / mixtral-8x22b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本生成\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mistralai/mixtral-8x22b-instruct-v0.1\",\n",
    "    messages=[{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":\"我对太阳系的行星非常感兴趣，特别是土星。请你使用中文提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"\n",
    "    }],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多轮对话\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mistralai/mixtral-8x22b-instruct-v0.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请你帮我将这个句子翻译为中文：keep a single spark to start a prairie fire\"},  # user代表用户，content为用户提问的内容\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一个火花来点燃草原之火\"},  # assistant代表glm4，content为glm4的回答\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译为更加优雅的句子。\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一星火种，点燃草原烈焰。\"},\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译成一句对偶句。\"}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本生成\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-large\",\n",
    "    messages=[{\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"我对太阳系的行星非常感兴趣，特别是土星。请你使用中文提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"\n",
    "    }],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多轮对话\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = mykey\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-large\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请你帮我将这个句子翻译为中文：keep a single spark to start a prairie fire\"},  # user代表用户，content为用户提问的内容\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一个火花来点燃草原之火\"},  # assistant代表glm4，content为glm4的回答\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译为更加优雅的句子。\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"保持一星火种，点燃草原烈焰。\"},\n",
    "        {\"role\": \"user\", \"content\": \"请你翻译成一句对偶句。\"}\n",
    "        ],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
